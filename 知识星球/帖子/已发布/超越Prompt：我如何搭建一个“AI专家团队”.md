## 超越Prompt：我如何搭建一个“AI专家团队”

大家好，我是William。

最近，社群里一个关于`Rules`的好问题，引发了我对自己日常AI协作框架的系统性思考。很多人在纠结`单次Prompt`、`Agent Prompt`和`Rules`到底该怎么用，感觉它们界限模糊。

今天，我想把这套完整的思考模型分享给大家，希望能帮助各位**从“写好一个Prompt”，进化到“管理一个AI专家团队”**。

---

### **核心理念：“专家团队” vs “环境法则”**

要理解这三者的关系，我们首先要建立一个核心比喻：

*   **`Agent Prompts`（专家角色）：** 这是在组建你的**“专家团队”**。每一个Agent提示词，都是一份精心设计的“岗位说明书”，详细定义了一个AI专家的人设、技能和思考模式（例如：“后端工程师Agent”、“视频脚本Agent”）。**它的本质是赋能——通过定义角色，召唤一个专家。**

*   **`Rules`（环境法则）：** 这是在设定团队的**“环境铁律”**。它像公司的基本法，所有成员都必须无条件遵守（例如：“永远用中文回复”）。**它的本质是约束——通过设定规则，划定底线。**

现在，我们再来看`单次Prompt`，它的角色就非常清晰了：

*   **`单次Prompt`（战术指令）：** 这是你向召唤来的“专家”下达的**“日常工作指令”**。

**所以，我的整套体系，核心就是“打磨和召唤不同的专家，然后给他们下达清晰的指令”。**

---

### **为什么我更依赖“专家”，而不是“法则”？**

这就回答了最初的问题：“为什么我总在提Agent，却很少提Rules？”

因为在解决复杂问题时，**一个定义清晰的“专家”远比一堆“法则”更强大、更灵活。**

*   一位“后端专家”Agent，天生就知道要遵循后端开发的最佳实践，我无需在`Rules`里把RESTful规范写一遍。
*   而如果我试图用一套复杂的`Rules`去管理所有Agent，很快就会陷入“规则冲突”的泥潭——“创意写作Agent”的规则和“代码审查Agent”的规则可能是完全相反的。

**这就像管理一个公司，你是更愿意招聘一堆有能力的专家，并相信他们的专业性；还是只招聘一堆小白，然后试图用一本厚厚的《员工手册》去规定他所有的行为？** 答案是显而易见的。

---

### **AI协作的“驾驶心法”**

现在，我们用另一个比喻来明确使用时机：

*   **单次Prompt是“手动挡”：** 它最灵活，能应对任何突发状况，需要你全神贯注，为每一次操作精细地换挡给油。**这是我们必须掌握的基本功。**

*   **Agent Prompt是“专家巡航模式”：** 当你要跑一段长途（比如开发一个新功能）时，你启动“后端专家”这个巡航模式，AI就会以专业、高效的方式自动驾驶，你只需要给出关键指令。

*   **Rules是“全局安全设定”：** 像是“自动紧急制动”或“车道保持”。你设定一次就忘了它，它在后台默默运行，保证不出基本的大格。比如，无论在什么巡航模式下，“永远说中文”这个安全设定都必须生效。

---

### **总结：我的AI协作三层模型**

至此，一个清晰的协作金字塔就浮现了：

*   **塔尖（高频应用）：战术指令 (单次Prompt)**
    *   *做什么：* 下达具体、一次性的任务。
    *   *怎么做：* 把“手动挡”练好，指令清晰、准确。

*   **塔身（核心支柱）：专家角色 (Agent Prompts)**
    *   *做什么：* 召唤最适合当前任务的“领域专家”。
    *   *怎么做：* 这是我们投入时间最多的地方，不断打磨和丰富我们的“专家库”。

*   **塔基（稳定地基）：环境法则 (Rules)**
    *   *做什么：* 设定全局的、极少数的、普适的“铁律”。
    *   *怎么做：* 极度克制，只放那些“非它不可”的通用规则。

希望这个包含了“为什么”和“怎么做”的完整模型，能真正帮到大家。

与各位共勉。 

---

**最后，留一个开放性问题给大家：**

这套三层模型是我个人实践的总结，但每个人的工作流都不同。

*   你在自己的AI工作流中，是如何权衡 `单次Prompt`、`Agent` 和 `Rules` 的？
*   你是否还有第四层、第五层的思考？

非常期待在评论区看到你的想法，让我们一起把这个模型打磨得更完善！