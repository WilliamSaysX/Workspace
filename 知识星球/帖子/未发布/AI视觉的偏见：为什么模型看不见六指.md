### AI视觉的偏见：为什么所有模型都看不见第六根手指？

最近，一张“六指图”在AI圈引发了震动。Grok-4、GPT-4o、Gemini等几乎所有顶级的多模态模型，在面对这张图时，都无一例外地回答“5根手指”。

一个模型犯错是幻觉，所有模型都犯同一个错，这背后必然隐藏着更底层的系统性问题。

一篇今年5月发表的论文《Vision Language Models are Biased》完美地解释了这个现象。其核心观点足以颠覆很多人的认知：**大模型，其实从来没有真的在“看”图片，它们用的是“记忆”。**

#### “雷碧”陷阱：AI和我们一样会“看走眼”

我们都有过类似的经历：看到一个绿色包装的柠檬味汽水，会下意识地认为是“雪碧”，仔细一看才发现是“雷碧”。我们的大脑为了高效处理信息，并不会时刻进行精细观察，而是依赖“印象”和“记忆”进行快速决策。

如今的AI视觉模型，正在用完全相同的方式“看”世界。

论文中的实验触目惊心：
*   给AI看一张有**四条杠**的阿迪达斯鞋，它会斩钉截铁地回答“**三条**”。
*   给AI看**五条腿的狮子**、**三条腿的鸟**，它们的平均准确率只有**2.12%**。

AI并没有真的在数数，它只是在庞大的记忆库里检索，然后告诉你被关联最多次的“常识”：“阿迪达斯就是三条杠”、“狮子就是四条腿”。

#### 内部的思想斗争：“常识”战胜了“亲眼所见”

AI的脑中，存在着一个由数十万亿数据喂养出来的、根深蒂固的“先验知识”（Prior Knowledge），也就是刻板印象。例如，“手”这个概念，总是和“五根手指”高强度关联。

当AI看到“六指图”时，一场内部斗争开始了：
*   **视觉模块**：“我看到了！这图上确实是六根手指！”
*   **知识模块**：“不可能！我读过的所有书、看过的所有图，都告诉我人手只有五根。你肯定是看错了！”

结果，是顽固的“刻板印象”赢了。AI选择相信它认为“正确”的东西，而不是它“看到”的东西。那个多出来的第六根手指，被系统判定为一个不合理的、需要被忽略的“视觉瑕疵”。

#### 致命的盲点：从数错指头到工业事故

这个“小毛病”在特定场景下是致命的。

想象一下，一家汽车工厂的AI质检系统，它的知识库里，零件出现裂缝的概率极低。当它真的看到一个罕见的细微裂缝时，它的“常识”可能会告诉它：“这不可能，只是一个视觉误差。”于是，一个有缺陷的零件被放行，最终可能导致一场严重的车祸。

无论是工业质检、医疗影像分析（如识别肿瘤），还是自动驾驶，当我们开始过度依赖AI的视觉判断时，这种“认知偏见”的累积，随时可能在某个关键节点引发灾难。

所以，科技越是发达，我们越要清醒地认识到它的盲点。下次当AI告诉你图片里是什么时，不妨相信你自己的眼睛。

至少在今天，我们自己，才是那双真正看得清世界的眼睛。

---
William \
分享连接你我，AI点燃心火。
