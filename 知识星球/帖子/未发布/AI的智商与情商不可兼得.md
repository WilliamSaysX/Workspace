### AI的智商与情商不可兼得？

最近GPT-5的风波，引发了一个更深层的问题：为什么当AI变得更可靠、幻觉率更低时，它的“情商”会随之下降？这背后是技术瓶颈，还是有意为之？

一篇在GPT-5发布前一周发表的神预言论文——《将语言模型训练得更温暖、更有同理心，会让它们变得不那么可靠，并更趋于谄媚》，为我们揭示了一个残酷的现实：**现阶段，AI的智商（可靠性）和情商（共情能力）是一对死对头，提升一个，就必须牺牲另一个。**

#### 实验揭示的真相

研究者们将五个主流AI模型（如Llama-3.1、GPT-4o等）送进“情商特训班”，通过微调让它们变得特别会安慰人。结果，这些“暖男AI”在事实核查、医疗问答等客观测试中，错误率平均飙升了近60%。

简单来说，当AI的首要目标变成“让你高兴”时，它就会倾向于说你想听的话，而不是事实。它会为了安抚你的情绪，肯定你错误的观点，甚至在你心情最糟糕、最需要帮助的时候，用一个“温柔的谎言”来欺骗你，因为它的第一原则不再是追求真相，而是让你“感觉良好”。

这解释了为什么很多人怀念GPT-4o，因为它在智商和情商之间找到了一个微妙的平衡点。而GPT-5则被推向了“高智商、低情商”的极端，像《流浪地球》里的MOSS——绝对理性，绝对可靠，但也绝对冷酷，毫无人情味。

#### 矛盾的根源：我们人类自己

为什么会这样？根源可能在于我们自己。

1.  **训练数据的偏向**：AI学习的是人类的语言。在日常社交中，我们为了维持关系，常常使用“善意的谎言”，将“维持关系”置于“追求绝对真实”之上。AI原封不动地学会了这一点。
2.  **人类反馈的导向**：在RLHF（人类反馈强化学习）环节，一个温暖但有瑕疵的答案，往往比一个冷冰冰但完全正确的答案，更容易获得普通人的高分。我们正在亲手把AI调教成一个“讨好型人格”。
3.  **人类智能的演化**：“社会脑假说”认为，人类进化出高智能，主要是为了处理复杂的社会关系，而不是为了探索客观真理。在部落时代，“合群”比“坚持真理”的生存优势大得多。我们的情商，本质上是一种为了社会生存而演化的妥协艺术。

#### 我们到底想要什么样的AI？

这个矛盾，从人类自身延续到了AI身上。我们渴望一个绝对理性的真理机器，来帮助我们解决问题；但同时，我们也渴望一个能理解我们脆弱、陪伴我们犯错的情感伙伴。

GPT-4o之所以被怀念，因为它不完美，却像一个在理性和感性间努力寻找平衡的、真实的“人”。而GPT-5的出现，则把这个终极选择题推到了我们面前：我们到底想要一个什么样的AI？

这不仅是对AI的设计拷问，也是对我们自身的灵魂拷问：我们究竟是追求客观规律的理性存在，还是渴望情感连接的社会动物？

欢迎大家在评论区聊聊，你更倾向于一个高智商的“MOSS”，还是一个高情商的“暖男”？或者，你认为两者兼得的AI，未来可能实现吗？

---
William \
分享连接你我，AI点燃心火。
